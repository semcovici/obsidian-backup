* computa os requisitos de recursos para a aplicação para o [[Cluster Manager]]
* gerencia todos os aspectos do ciclo de vida de um job, incluindo a alocação dinâmica de recursos
* Distribui e agenda as tarefas a serem realizadas pelos spark executors
* Reage as falhas nos executors ou nodes, pedindo recursos alternativos para o [[Cluster Manager]] caso precise
* Acompanha os status dos executors e monitora o progresso